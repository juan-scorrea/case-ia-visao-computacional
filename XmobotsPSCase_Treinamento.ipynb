{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"ancora\"></a>\n",
        "# Case IA e Visão Computacional - Treinamento\n",
        "\n",
        "No presente notebook, encontra-se o script usado para o treinamento do modelo de classificação de imagens de árvores e imagens de solo. Um sumário do notebook pode ser visto a seguir.\n",
        "\n",
        "## Sumário\n",
        "1. [Inicializacao](#inicializacao)\n",
        "2. [Organização e Limpeza dos dados](#organizacao)\n",
        "3. [*Feature Engineering*](#feat_eng)\n",
        "4. [Treinamento do modelo (CNN)](#CNN)"
      ],
      "metadata": {
        "id": "gR0Lk_AVtvJ5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inicialização <a name=\"inicializacao\"></a>"
      ],
      "metadata": {
        "id": "fzsfj100xdsc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importando bibliotecas básicas:"
      ],
      "metadata": {
        "id": "gA8r2fmP3_lN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "TQKwaTtQnGLt"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importando os dados (*.zip*):"
      ],
      "metadata": {
        "id": "D6BWH1KhmZOy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "8mM89JiT-Oq8",
        "outputId": "4bc54d72-9fe9-40d9-84f5-0fd52a72f3f1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9a3d8546-780b-4456-a90d-dd1237773874\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-9a3d8546-780b-4456-a90d-dd1237773874\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Data.zip to Data.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "zipfile = '/content/Data.zip'\n",
        "unzip_to = '/content/XMB/'\n",
        "shutil.unpack_archive(zipfile, unzip_to)"
      ],
      "metadata": {
        "id": "SMrKXa3nA4K7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CATEGORIES = [\"soil\",\"tree\"]\n",
        "DATADIR = \"/content/XMB/Data\"\n",
        "\n",
        "# lista com o nome das imagens\n",
        "imgs_list = os.listdir(DATADIR)"
      ],
      "metadata": {
        "id": "HEmQePvnnLbM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Voltar ao topo](#ancora)"
      ],
      "metadata": {
        "id": "nC-v9ORhzcYE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Organização e Limpeza dos dados <a name=\"organizacao\"></a>"
      ],
      "metadata": {
        "id": "DP5RyiWl0DCb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Permitindo verificar se os dados estão desbalanceados ou não, a função a seguir conta a quantidade de amostras em cada categoria. "
      ],
      "metadata": {
        "id": "KmQP2asqMkpq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_samples(c_list):\n",
        "\n",
        "  samples_count = {'soil': 0,'tree': 0}\n",
        "\n",
        "  for sample in c_list:\n",
        "    if sample[1] == 0:\n",
        "      samples_count['soil'] = samples_count['soil']+1\n",
        "    elif sample[1] == 1:\n",
        "      samples_count['tree'] = samples_count['tree']+1\n",
        "\n",
        "  print(samples_count)"
      ],
      "metadata": {
        "id": "C_DiSz2y2E-F"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inicializando função para separar e balancear dados. "
      ],
      "metadata": {
        "id": "z4hUFKviNnWA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def data_split(d_list, split_prop = np.array([0.8,0.1,0.1]), balance = True):\n",
        "\n",
        "  # garantindo que a soma da divisão entre treinamento, validação e teste é 1.\n",
        "  try:\n",
        "    np.sum(split_prop) == 1.0\n",
        "  except:\n",
        "    print('split_prop sum != 1.')\n",
        "\n",
        "  else:\n",
        "    soil_list = []\n",
        "    tree_list = []\n",
        "\n",
        "    train_list = []\n",
        "    val_list = []\n",
        "    test_list = []\n",
        "\n",
        "    # separando as imagens por classificação.\n",
        "    for name, label in d_list:\n",
        "\n",
        "      # carregando as imagens\n",
        "      img_array = cv2.imread(os.path.join(DATADIR,name), cv2.IMREAD_COLOR)\n",
        "      img_array_rgb = cv2.cvtColor(img_array, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "      if label:\n",
        "        tree_list.append([name,label,img_array_rgb])\n",
        "      else:\n",
        "        soil_list.append([name,label,img_array_rgb])\n",
        "\n",
        "    # balanceando os dados, caso solicitado.\n",
        "    if balance:\n",
        "      lower = min(len(tree_list),len(soil_list))\n",
        "\n",
        "      tree_list = tree_list[:lower]\n",
        "      soil_list = soil_list[:lower]\n",
        "\n",
        "    # definindo os valores em que as listas serão separadas.\n",
        "    train_list_ts = int(len(tree_list)*split_prop[0])\n",
        "    train_list_ss = int(len(soil_list)*split_prop[0])\n",
        "    \n",
        "    val_list_ts = train_list_ts + int(len(tree_list)*split_prop[1])\n",
        "    val_list_ss = train_list_ss + int(len(soil_list)*split_prop[1])\n",
        "\n",
        "    # dividindo em teste, treino e validação.\n",
        "    train_list = tree_list[:train_list_ts] + soil_list[:train_list_ss]\n",
        "    val_list = tree_list[train_list_ts:val_list_ts] + soil_list[train_list_ss:val_list_ss]\n",
        "    test_list = tree_list[val_list_ts:] + soil_list[val_list_ss:]\n",
        "\n",
        "    random.shuffle(train_list)\n",
        "    random.shuffle(val_list)\n",
        "    random.shuffle(test_list)\n",
        "\n",
        "    return train_list, val_list, test_list\n"
      ],
      "metadata": {
        "id": "BI0a1jJn2JtE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dado que há imagens com falhas (pixels pretos), a função a seguir retorna a imagem com os pixels falhos tendo seus valores RGB alterados para a média de cada componente."
      ],
      "metadata": {
        "id": "TnwL_v9QPMn5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def avg_on_missing_values(bad_img, print_media = False):\n",
        "  R_sum = 0\n",
        "  G_sum = 0\n",
        "  B_sum = 0\n",
        "  k = 0\n",
        "\n",
        "  # obtendo a média de cada componente RGB dos pixels não falhos.\n",
        "  for i in range(len(bad_img)):\n",
        "    for j in range(len(bad_img[i])):\n",
        "      if bad_img[i,j].any() != 0:\n",
        "        k = k+1\n",
        "\n",
        "        R_sum = R_sum + bad_img[i,j,0]\n",
        "        G_sum = G_sum + bad_img[i,j,1]\n",
        "        B_sum = B_sum + bad_img[i,j,2]\n",
        "\n",
        "  R_mean = R_sum/k\n",
        "  G_mean = G_sum/k\n",
        "  B_mean = B_sum/k\n",
        "\n",
        "  pixel_mean = np.array([R_mean,G_mean,B_mean])\n",
        "\n",
        "  if print_media:\n",
        "    print(f'[R={pixel_mean[0]:.1f},  G={pixel_mean[1]:.1f}, B={pixel_mean[2]:.1f} ]')\n",
        "\n",
        "  # substituindo os pixels falhos pela média obtida.\n",
        "  for i in range(len(bad_img)):\n",
        "    for j in range(len(bad_img[i])):\n",
        "      if bad_img[i,j].any() == 0:\n",
        "        bad_img[i,j] = pixel_mean.astype('uint8')\n",
        "  \n",
        "  return(bad_img)"
      ],
      "metadata": {
        "id": "Jtb4dgBm1pgm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Realizando o balanceamento e limpeza dos dados\n",
        "\n",
        "*   Será utilizado a divisão dos dados de (8:1:1) para treinamento,validação e teste, respectivamente.\n",
        "\n",
        "*   Tendo em vista que há 2 vezes mais amostras de imagens de solo do que amostras de imagens de árvores, será aplicado o balanceamento dos dados igualando o número de amostras.\n",
        "\n"
      ],
      "metadata": {
        "id": "H3ozjs8qTSPF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# carregando a lista de imagens\n",
        "data_list = []\n",
        "for img in imgs_list:\n",
        "  class_num = CATEGORIES.index(img[5:9])\n",
        "\n",
        "  # [nome_do_arquivo, classificação]\n",
        "  data_list.append([img, class_num])\n",
        "\n",
        "print('Número de amostras antes do balanceamento:')\n",
        "count_samples(data_list)\n",
        "\n",
        "# dividindo e balanceando os dados\n",
        "# [nome_do_arquivo, classificação, imagem]\n",
        "train_list, val_list, test_list = data_split(data_list)\n",
        "\n",
        "# corrigindo imagens com pixels falhos\n",
        "train_list_corrected = []\n",
        "val_list_corrected = []\n",
        "test_list_corrected = []\n",
        "\n",
        "for name, label, img in train_list:\n",
        "  train_list_corrected.append([name, label, avg_on_missing_values(img)])\n",
        "\n",
        "for name, label, img in val_list:\n",
        "  val_list_corrected.append([name, label, avg_on_missing_values(img)])\n",
        "\n",
        "for name, label, img in test_list:\n",
        "  test_list_corrected.append([name, label, avg_on_missing_values(img)])\n",
        "\n",
        "print('\\nNúmero de amostras após o balanceamento:')\n",
        "print('Treino:')\n",
        "count_samples(train_list_corrected)\n",
        "print('Validação')\n",
        "count_samples(val_list_corrected)\n",
        "print('Teste:')\n",
        "count_samples(test_list_corrected)"
      ],
      "metadata": {
        "id": "NI6AAnsJTr2x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4049f298-fef0-4c83-ad60-c590b0e5af06"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de amostras antes do balanceamento:\n",
            "{'soil': 4448, 'tree': 2224}\n",
            "\n",
            "Número de amostras após o balanceamento:\n",
            "Treino:\n",
            "{'soil': 1779, 'tree': 1779}\n",
            "Validação\n",
            "{'soil': 222, 'tree': 222}\n",
            "Teste:\n",
            "{'soil': 223, 'tree': 223}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Voltar ao topo](#ancora)"
      ],
      "metadata": {
        "id": "nti7GnPndGWg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Engineering <a name=\"feat_eng\"></a>"
      ],
      "metadata": {
        "id": "W4pVn3yCc5wR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Procurando destacar a diferença de cores, sabendo que a imagem encontra-se em RGB e R é o valor da componente vermelha do pixel; G é o valor da componente verde do pixel e; B é o valor da componente azul do pixel; Os pixels serão normalizados de acordo com a seguinte equação:\n",
        "\n",
        "$$ pixel = [\\frac{R}{R+G+B}, \\frac{G}{R+G+B}, \\frac{B}{R+G+B} ]$$\n",
        "\n",
        "Inicializando função de normalização dos pixels. "
      ],
      "metadata": {
        "id": "WEw17NRn4YMy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_rgb(rgb_img, printable = False):\n",
        "  # se 'printable' inicializado como 'True', a imagem da saída terá os valores entre 0 e 255\n",
        "  \n",
        "  rgb_img = rgb_img.astype('float32')\n",
        "\n",
        "  # recuperando uma lista separada para cada componente RGB do pixel\n",
        "  r = rgb_img[:,:,0]\n",
        "  g = rgb_img[:,:,1]\n",
        "  b = rgb_img[:,:,2]\n",
        "\n",
        "  norm_img = np.zeros(rgb_img.shape, np.float32)\n",
        "\n",
        "  if printable:\n",
        "    printable_norm_img = np.zeros(rgb_img.shape, np.uint8)\n",
        "\n",
        "  # realizando a operação de normalização para cada pixel\n",
        "  for i in range(len(rgb_img)):\n",
        "    for j in range(len(rgb_img[i])):\n",
        "\n",
        "      sum = r[i,j] + g[i,j] + b[i,j]\n",
        "      \n",
        "      norm_img[i,j] = np.array([r[i,j]/sum, g[i,j]/sum, b[i,j]/sum])\n",
        "      if printable:\n",
        "        printable_norm_img[i,j] = np.array(norm_img[i,j]*255.0).astype('uint8')\n",
        "        \n",
        "  if printable:\n",
        "    norm_img = printable_norm_img\n",
        "        \n",
        "  return norm_img"
      ],
      "metadata": {
        "id": "XVfixbjH1_L0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalizando as imagens"
      ],
      "metadata": {
        "id": "2VyjHE64hXMp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "norm_train = []\n",
        "norm_val = []\n",
        "norm_test = []\n",
        "\n",
        "for name, label, img in train_list_corrected:\n",
        "  norm_train.append([name, label, normalize_rgb(img)])\n",
        "\n",
        "for name, label, img in val_list_corrected:\n",
        "  norm_val.append([name, label, normalize_rgb(img)])\n",
        "\n",
        "for name, label, img in test_list_corrected:\n",
        "  norm_test.append([name, label, normalize_rgb(img)])"
      ],
      "metadata": {
        "id": "3LENwzYshlLs"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Organizando as listas em um dicionário composto por DataFrames"
      ],
      "metadata": {
        "id": "qH2AZvbU_Kcj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "processed_data_dict = {}\n",
        "def list_to_dataframe(key, list_corrected):\n",
        "  name_list = []\n",
        "  label_list = []\n",
        "  normalized_imgs_list = []\n",
        "  \n",
        "  aux_data_dict = {}\n",
        "\n",
        "  for name, label, img in list_corrected:\n",
        "    name_list.append(name)\n",
        "    label_list.append(label)\n",
        "    normalized_imgs_list.append(img)\n",
        "\n",
        "  aux_data_dict = {'name':name_list, 'label':label_list, 'image':normalized_imgs_list}\n",
        "  processed_data_dict[key] = pd.DataFrame(aux_data_dict)\n",
        "\n",
        "list_to_dataframe('train', norm_train)\n",
        "list_to_dataframe('val', norm_val)\n",
        "list_to_dataframe('test', norm_test)"
      ],
      "metadata": {
        "id": "AemThAba13-p"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exportando os dados após pré-processamento:"
      ],
      "metadata": {
        "id": "NR2lxrzFidZw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "pickle_out = open(\"/content/XMB/processed_data.pickle\",\"wb\")\n",
        "pickle.dump(processed_data_dict, pickle_out)\n",
        "pickle_out.close()"
      ],
      "metadata": {
        "id": "5fIjgTRGiqaH"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Voltar ao topo](#ancora)"
      ],
      "metadata": {
        "id": "zNpLJajmHpgZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementação do modelo (CNN) <a name=\"CNN\"></a>"
      ],
      "metadata": {
        "id": "HIHR1y86XtFH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importando as bibliotecas"
      ],
      "metadata": {
        "id": "5i5fbQO5_n4R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D \n",
        "from tensorflow.keras.callbacks import TensorBoard,EarlyStopping, ModelCheckpoint\n",
        "import pickle\n",
        "import time"
      ],
      "metadata": {
        "id": "uqimiLA2xmgi"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inicializando dados"
      ],
      "metadata": {
        "id": "dzPTNP3fAKgM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "processed_data_dict = pickle.load(open(\"/content/XMB/processed_data.pickle\",\"rb\"))"
      ],
      "metadata": {
        "id": "no14mKsX_kBc"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definindo função para separar dados entre input (X) e output (y)."
      ],
      "metadata": {
        "id": "QmQd9kqT0vN3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_Xy(processed_data):\n",
        "  X = []\n",
        "  y = []\n",
        "\n",
        "  IMG_SIZE = processed_data['image'][0].shape[0]\n",
        "\n",
        "  for features, label in zip(processed_data['image'],processed_data['label']):\n",
        "    X.append(features)\n",
        "    y.append(label)\n",
        "\n",
        "  # realizando reshape para usar como input no CNN.\n",
        "  X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
        "  y = np.array(y)\n",
        "\n",
        "  return X,y\n",
        "\n",
        "X_train, y_train = split_Xy(processed_data_dict['train'])\n",
        "X_val, y_val = split_Xy(processed_data_dict['val'])\n",
        "X_test, y_test = split_Xy(processed_data_dict['test'])"
      ],
      "metadata": {
        "id": "tS1O-5cS2Zcs"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Treinando o modelo:\n",
        "\n",
        "*   Devido a sua eficácia em tarefas de classificação de imagens, o modelo implementado foi a Rede Neural Convolucional (CNN)\n",
        "*   O algoritmo irá realizar um Grid Search entre 3 valores de *dense layers*, *layer sizes* e *conv layers*.\n",
        "*   O número de épocas foi definido como 50, porém está sendo incluso um *EarlyStopping* de paciencia 5 monitorando as perdas na validação (*val_loss*).\n",
        "*   O modelo definido como o melhor para cada conjunto de hyperparâmetros no Grid Search é aquele que teve a melhor acurácia na validação (*val_acc*) dentre todas as épocas.\n",
        "\n"
      ],
      "metadata": {
        "id": "Vzev2QoDDD9p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "dense_layers = [0, 1, 2]\n",
        "layer_sizes = [32, 64, 128]\n",
        "conv_layers = [1, 2, 3]\n",
        "\n",
        "total_tqdm = len(dense_layers)*len(layer_sizes)*len(conv_layers)\n",
        "\n",
        "best_results = [0,0]\n",
        "\n",
        "with tqdm(total=total_tqdm) as pbar:\n",
        "  for dense_layer in dense_layers:\n",
        "      for layer_size in layer_sizes:\n",
        "          for conv_layer in conv_layers:\n",
        "            \n",
        "            NAME = \"{}-conv-{}-nodes{}-dense-{}\".format(conv_layer, layer_size, dense_layer, int(time.time()))\n",
        "            tensorboard = TensorBoard(log_dir='/content/XMB/logs/{}'.format(NAME))\n",
        "\n",
        "            model = Sequential()\n",
        "\n",
        "            model.add(Conv2D(layer_size, (3,3), input_shape = X_train.shape[1:]))\n",
        "            model.add(Activation(\"relu\"))\n",
        "            model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "            model.add(Dropout(0.2))\n",
        "\n",
        "            for l in range(conv_layer-1):\n",
        "              model.add(Conv2D(layer_size, (3,3)))\n",
        "              model.add(Activation(\"relu\"))\n",
        "              model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "              model.add(Dropout(0.2))\n",
        "\n",
        "            model.add(Flatten())\n",
        "\n",
        "            for l in range(dense_layer):  \n",
        "              model.add(Dense(layer_size))\n",
        "              model.add(Activation(\"relu\"))\n",
        "              model.add(Dropout(0.2))\n",
        "\n",
        "            model.add(Dense(64))\n",
        "            model.add(Activation(\"relu\"))\n",
        "            model.add(Dropout(0.2))\n",
        "\n",
        "            model.add(Dense(1))\n",
        "            model.add(Activation('sigmoid'))\n",
        "\n",
        "            model.compile(loss=\"binary_crossentropy\",\n",
        "                        optimizer=\"adam\",\n",
        "                        metrics=['accuracy'])\n",
        "\n",
        "            model.fit(X_train, y_train, \n",
        "                      batch_size=32,\n",
        "                      epochs = 50,\n",
        "                      verbose=0,\n",
        "                      validation_data = (X_val,y_val),\n",
        "                      callbacks=[tensorboard,\n",
        "                                 EarlyStopping(monitor='val_loss', \n",
        "                                              mode='min', \n",
        "                                              patience=5,\n",
        "                                              verbose=0,\n",
        "                                              restore_best_weights=False),\n",
        "                                 ModelCheckpoint('/content/XMB/best_model.h5',\n",
        "                                                monitor='val_accuracy',\n",
        "                                                mode='max',\n",
        "                                                verbose=0,\n",
        "                                                save_best_only=True)])\n",
        "            \n",
        "            # avaliando o modelo\n",
        "            saved_model = load_model('/content/XMB/best_model.h5')\n",
        "            results = saved_model.evaluate(X_test, y_test, batch_size=32, verbose=0)\n",
        "\n",
        "            # verificando se o modelo atual é o melhor\n",
        "            cur_loss, cur_acc = results\n",
        "            best_loss, best_acc = best_results \n",
        "\n",
        "            if cur_acc>best_acc or (cur_acc == best_acc and cur_loss<best_loss): \n",
        "              best_results = results\n",
        "\n",
        "              param_dct = {'dense_layer': dense_layer,\n",
        "                          'layer_size': layer_size,\n",
        "                          'conv_layer': conv_layer}\n",
        "              \n",
        "              model_dct = {'name':NAME,\n",
        "                            'model':saved_model,\n",
        "                            'param':param_dct,\n",
        "                            'results':results}\n",
        "\n",
        "            pbar.update(1)\n",
        "\n",
        "print(\"Melhor modelo encontrado:\\n\")\n",
        "print(f\"acurácia(accuracy): {model_dct['results'][1]}\")\n",
        "print(f\"perdas(loss): {model_dct['results'][0]}\\n\")\n",
        "print(\"Parâmetros:\")\n",
        "print(model_dct['param'])\n",
        "model_dct['model'].save('/content/XMB/model/trees-vs-soil-CNN.h5')"
      ],
      "metadata": {
        "id": "5r63PyltCTmQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44f59e76-8fbb-4b94-a7c1-cd96f88f688d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 27/27 [12:51<00:00, 28.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Melhor modelo encontrado:\n",
            "\n",
            "acurácia(accuracy): 0.9192824959754944\n",
            "perdas(loss): 0.2378302961587906\n",
            "\n",
            "Parâmetros:\n",
            "{'dense_layer': 2, 'layer_size': 32, 'conv_layer': 3}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exportando modelo e dados do Tensorboard."
      ],
      "metadata": {
        "id": "0AU_HM-3KyLs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/XMB/model.zip /content/XMB/model"
      ],
      "metadata": {
        "id": "07oVgEYrKJA-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fef5cc8-64dd-41c3-b7c1-b61e8c2a979d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/XMB/model/ (stored 0%)\n",
            "  adding: content/XMB/model/trees-vs-soil-CNN.h5 (deflated 25%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/XMB/logs.zip /content/XMB/logs"
      ],
      "metadata": {
        "id": "fdGZO1-pKQ3G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1463aeef-5848-47f4-aa1b-602867a1bad9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/XMB/logs/ (stored 0%)\n",
            "  adding: content/XMB/logs/1-conv-64-nodes1-dense-1685025865/ (stored 0%)\n",
            "  adding: content/XMB/logs/1-conv-64-nodes1-dense-1685025865/train/ (stored 0%)\n",
            "  adding: content/XMB/logs/1-conv-64-nodes1-dense-1685025865/train/events.out.tfevents.1685025865.4d1b732e184a.169.24.v2 (deflated 75%)\n",
            "  adding: content/XMB/logs/1-conv-64-nodes1-dense-1685025865/validation/ (stored 0%)\n",
            "  adding: content/XMB/logs/1-conv-64-nodes1-dense-1685025865/validation/events.out.tfevents.1685025868.4d1b732e184a.169.25.v2 (deflated 76%)\n",
            "  adding: content/XMB/logs/3-conv-64-nodes1-dense-1685025898/ (stored 0%)\n",
            "  adding: content/XMB/logs/3-conv-64-nodes1-dense-1685025898/train/ (stored 0%)\n",
            "  adding: content/XMB/logs/3-conv-64-nodes1-dense-1685025898/train/events.out.tfevents.1685025898.4d1b732e184a.169.28.v2 (deflated 80%)\n",
            "  adding: content/XMB/logs/3-conv-64-nodes1-dense-1685025898/validation/ (stored 0%)\n",
            "  adding: content/XMB/logs/3-conv-64-nodes1-dense-1685025898/validation/events.out.tfevents.1685025902.4d1b732e184a.169.29.v2 (deflated 76%)\n",
            "  adding: content/XMB/logs/1-conv-128-nodes1-dense-1685025941/ (stored 0%)\n",
            "  adding: content/XMB/logs/1-conv-128-nodes1-dense-1685025941/train/ (stored 0%)\n",
            "  adding: content/XMB/logs/1-conv-128-nodes1-dense-1685025941/train/events.out.tfevents.1685025941.4d1b732e184a.169.30.v2 (deflated 76%)\n",
            "  adding: content/XMB/logs/1-conv-128-nodes1-dense-1685025941/validation/ (stored 0%)\n",
            "  adding: content/XMB/logs/1-conv-128-nodes1-dense-1685025941/validation/events.out.tfevents.1685025944.4d1b732e184a.169.31.v2 (deflated 77%)\n",
            "  adding: content/XMB/logs/1-conv-128-nodes2-dense-1685026153/ (stored 0%)\n",
            "  adding: content/XMB/logs/1-conv-128-nodes2-dense-1685026153/train/ (stored 0%)\n",
            "  adding: content/XMB/logs/1-conv-128-nodes2-dense-1685026153/train/events.out.tfevents.1685026153.4d1b732e184a.169.48.v2 (deflated 78%)\n",
            "  adding: content/XMB/logs/1-conv-128-nodes2-dense-1685026153/validation/ (stored 0%)\n",
            "  adding: content/XMB/logs/1-conv-128-nodes2-dense-1685026153/validation/events.out.tfevents.1685026157.4d1b732e184a.169.49.v2 (deflated 76%)\n",
            "  adding: content/XMB/logs/1-conv-64-nodes0-dense-1685025595/ (stored 0%)\n",
            "  adding: content/XMB/logs/1-conv-64-nodes0-dense-1685025595/train/ (stored 0%)\n",
            "  adding: content/XMB/logs/1-conv-64-nodes0-dense-1685025595/train/events.out.tfevents.1685025596.4d1b732e184a.169.6.v2 (deflated 73%)\n",
            "  adding: content/XMB/logs/1-conv-64-nodes0-dense-1685025595/validation/ (stored 0%)\n",
            "  adding: content/XMB/logs/1-conv-64-nodes0-dense-1685025595/validation/events.out.tfevents.1685025599.4d1b732e184a.169.7.v2 (deflated 76%)\n",
            "  adding: content/XMB/logs/2-conv-128-nodes2-dense-1685026196/ (stored 0%)\n",
            "  adding: content/XMB/logs/2-conv-128-nodes2-dense-1685026196/train/ (stored 0%)\n",
            "  adding: content/XMB/logs/2-conv-128-nodes2-dense-1685026196/train/events.out.tfevents.1685026196.4d1b732e184a.169.50.v2 (deflated 81%)\n",
            "  adding: content/XMB/logs/2-conv-128-nodes2-dense-1685026196/validation/ (stored 0%)\n",
            "  adding: content/XMB/logs/2-conv-128-nodes2-dense-1685026196/validation/events.out.tfevents.1685026200.4d1b732e184a.169.51.v2 (deflated 75%)\n",
            "  adding: content/XMB/logs/2-conv-64-nodes2-dense-1685026104/ (stored 0%)\n",
            "  adding: content/XMB/logs/2-conv-64-nodes2-dense-1685026104/train/ (stored 0%)\n",
            "  adding: content/XMB/logs/2-conv-64-nodes2-dense-1685026104/train/events.out.tfevents.1685026104.4d1b732e184a.169.44.v2 (deflated 80%)\n",
            "  adding: content/XMB/logs/2-conv-64-nodes2-dense-1685026104/validation/ (stored 0%)\n",
            "  adding: content/XMB/logs/2-conv-64-nodes2-dense-1685026104/validation/events.out.tfevents.1685026108.4d1b732e184a.169.45.v2 (deflated 76%)\n",
            "  adding: content/XMB/logs/2-conv-32-nodes2-dense-1685026048/ (stored 0%)\n",
            "  adding: content/XMB/logs/2-conv-32-nodes2-dense-1685026048/train/ (stored 0%)\n",
            "  adding: content/XMB/logs/2-conv-32-nodes2-dense-1685026048/train/events.out.tfevents.1685026048.4d1b732e184a.169.38.v2 (deflated 81%)\n",
            "  adding: content/XMB/logs/2-conv-32-nodes2-dense-1685026048/validation/ (stored 0%)\n",
            "  adding: content/XMB/logs/2-conv-32-nodes2-dense-1685026048/validation/events.out.tfevents.1685026051.4d1b732e184a.169.39.v2 (deflated 75%)\n",
            "  adding: content/XMB/logs/3-conv-32-nodes0-dense-1685025553/ (stored 0%)\n",
            "  adding: content/XMB/logs/3-conv-32-nodes0-dense-1685025553/train/ (stored 0%)\n",
            "  adding: content/XMB/logs/3-conv-32-nodes0-dense-1685025553/train/events.out.tfevents.1685025553.4d1b732e184a.169.4.v2 (deflated 79%)\n",
            "  adding: content/XMB/logs/3-conv-32-nodes0-dense-1685025553/validation/ (stored 0%)\n",
            "  adding: content/XMB/logs/3-conv-32-nodes0-dense-1685025553/validation/events.out.tfevents.1685025556.4d1b732e184a.169.5.v2 (deflated 77%)\n",
            "  adding: content/XMB/logs/1-conv-32-nodes2-dense-1685026036/ (stored 0%)\n",
            "  adding: content/XMB/logs/1-conv-32-nodes2-dense-1685026036/train/ (stored 0%)\n",
            "  adding: content/XMB/logs/1-conv-32-nodes2-dense-1685026036/train/events.out.tfevents.1685026036.4d1b732e184a.169.36.v2 (deflated 78%)\n",
            "  adding: content/XMB/logs/1-conv-32-nodes2-dense-1685026036/validation/ (stored 0%)\n",
            "  adding: content/XMB/logs/1-conv-32-nodes2-dense-1685026036/validation/events.out.tfevents.1685026039.4d1b732e184a.169.37.v2 (deflated 75%)\n",
            "  adding: content/XMB/logs/2-conv-64-nodes0-dense-1685025611/ (stored 0%)\n",
            "  adding: content/XMB/logs/2-conv-64-nodes0-dense-1685025611/train/ (stored 0%)\n",
            "  adding: content/XMB/logs/2-conv-64-nodes0-dense-1685025611/train/events.out.tfevents.1685025612.4d1b732e184a.169.8.v2 (deflated 76%)\n",
            "  adding: content/XMB/logs/2-conv-64-nodes0-dense-1685025611/validation/ (stored 0%)\n",
            "  adding: content/XMB/logs/2-conv-64-nodes0-dense-1685025611/validation/events.out.tfevents.1685025614.4d1b732e184a.169.9.v2 (deflated 77%)\n",
            "  adding: content/XMB/logs/1-conv-32-nodes1-dense-1685025784/ (stored 0%)\n",
            "  adding: content/XMB/logs/1-conv-32-nodes1-dense-1685025784/train/ (stored 0%)\n",
            "  adding: content/XMB/logs/1-conv-32-nodes1-dense-1685025784/train/events.out.tfevents.1685025785.4d1b732e184a.169.18.v2 (deflated 75%)\n",
            "  adding: content/XMB/logs/1-conv-32-nodes1-dense-1685025784/validation/ (stored 0%)\n",
            "  adding: content/XMB/logs/1-conv-32-nodes1-dense-1685025784/validation/events.out.tfevents.1685025787.4d1b732e184a.169.19.v2 (deflated 78%)\n",
            "  adding: content/XMB/logs/3-conv-128-nodes1-dense-1685025993/ (stored 0%)\n",
            "  adding: content/XMB/logs/3-conv-128-nodes1-dense-1685025993/train/ (stored 0%)\n",
            "  adding: content/XMB/logs/3-conv-128-nodes1-dense-1685025993/train/events.out.tfevents.1685025993.4d1b732e184a.169.34.v2 (deflated 81%)\n",
            "  adding: content/XMB/logs/3-conv-128-nodes1-dense-1685025993/validation/ (stored 0%)\n",
            "  adding: content/XMB/logs/3-conv-128-nodes1-dense-1685025993/validation/events.out.tfevents.1685025997.4d1b732e184a.169.35.v2 (deflated 75%)\n",
            "  adding: content/XMB/logs/3-conv-32-nodes2-dense-1685026061/ (stored 0%)\n",
            "  adding: content/XMB/logs/3-conv-32-nodes2-dense-1685026061/train/ (stored 0%)\n",
            "  adding: content/XMB/logs/3-conv-32-nodes2-dense-1685026061/train/events.out.tfevents.1685026062.4d1b732e184a.169.40.v2 (deflated 81%)\n",
            "  adding: content/XMB/logs/3-conv-32-nodes2-dense-1685026061/validation/ (stored 0%)\n",
            "  adding: content/XMB/logs/3-conv-32-nodes2-dense-1685026061/validation/events.out.tfevents.1685026065.4d1b732e184a.169.41.v2 (deflated 77%)\n",
            "  adding: content/XMB/logs/2-conv-64-nodes1-dense-1685025880/ (stored 0%)\n",
            "  adding: content/XMB/logs/2-conv-64-nodes1-dense-1685025880/train/ (stored 0%)\n",
            "  adding: content/XMB/logs/2-conv-64-nodes1-dense-1685025880/train/events.out.tfevents.1685025880.4d1b732e184a.169.26.v2 (deflated 79%)\n",
            "  adding: content/XMB/logs/2-conv-64-nodes1-dense-1685025880/validation/ (stored 0%)\n",
            "  adding: content/XMB/logs/2-conv-64-nodes1-dense-1685025880/validation/events.out.tfevents.1685025883.4d1b732e184a.169.27.v2 (deflated 76%)\n",
            "  adding: content/XMB/logs/1-conv-128-nodes0-dense-1685025656/ (stored 0%)\n",
            "  adding: content/XMB/logs/1-conv-128-nodes0-dense-1685025656/train/ (stored 0%)\n",
            "  adding: content/XMB/logs/1-conv-128-nodes0-dense-1685025656/train/events.out.tfevents.1685025656.4d1b732e184a.169.12.v2 (deflated 73%)\n",
            "  adding: content/XMB/logs/1-conv-128-nodes0-dense-1685025656/validation/ (stored 0%)\n",
            "  adding: content/XMB/logs/1-conv-128-nodes0-dense-1685025656/validation/events.out.tfevents.1685025659.4d1b732e184a.169.13.v2 (deflated 78%)\n",
            "  adding: content/XMB/logs/1-conv-32-nodes0-dense-1685025490/ (stored 0%)\n",
            "  adding: content/XMB/logs/1-conv-32-nodes0-dense-1685025490/train/ (stored 0%)\n",
            "  adding: content/XMB/logs/1-conv-32-nodes0-dense-1685025490/train/events.out.tfevents.1685025494.4d1b732e184a.169.0.v2 (deflated 74%)\n",
            "  adding: content/XMB/logs/1-conv-32-nodes0-dense-1685025490/validation/ (stored 0%)\n",
            "  adding: content/XMB/logs/1-conv-32-nodes0-dense-1685025490/validation/events.out.tfevents.1685025505.4d1b732e184a.169.1.v2 (deflated 78%)\n",
            "  adding: content/XMB/logs/2-conv-32-nodes1-dense-1685025806/ (stored 0%)\n",
            "  adding: content/XMB/logs/2-conv-32-nodes1-dense-1685025806/train/ (stored 0%)\n",
            "  adding: content/XMB/logs/2-conv-32-nodes1-dense-1685025806/train/events.out.tfevents.1685025806.4d1b732e184a.169.20.v2 (deflated 78%)\n",
            "  adding: content/XMB/logs/2-conv-32-nodes1-dense-1685025806/validation/ (stored 0%)\n",
            "  adding: content/XMB/logs/2-conv-32-nodes1-dense-1685025806/validation/events.out.tfevents.1685025809.4d1b732e184a.169.21.v2 (deflated 76%)\n",
            "  adding: content/XMB/logs/3-conv-64-nodes2-dense-1685026123/ (stored 0%)\n",
            "  adding: content/XMB/logs/3-conv-64-nodes2-dense-1685026123/train/ (stored 0%)\n",
            "  adding: content/XMB/logs/3-conv-64-nodes2-dense-1685026123/train/events.out.tfevents.1685026124.4d1b732e184a.169.46.v2 (deflated 81%)\n",
            "  adding: content/XMB/logs/3-conv-64-nodes2-dense-1685026123/validation/ (stored 0%)\n",
            "  adding: content/XMB/logs/3-conv-64-nodes2-dense-1685026123/validation/events.out.tfevents.1685026127.4d1b732e184a.169.47.v2 (deflated 78%)\n",
            "  adding: content/XMB/logs/3-conv-32-nodes1-dense-1685025822/ (stored 0%)\n",
            "  adding: content/XMB/logs/3-conv-32-nodes1-dense-1685025822/train/ (stored 0%)\n",
            "  adding: content/XMB/logs/3-conv-32-nodes1-dense-1685025822/train/events.out.tfevents.1685025823.4d1b732e184a.169.22.v2 (deflated 80%)\n",
            "  adding: content/XMB/logs/3-conv-32-nodes1-dense-1685025822/validation/ (stored 0%)\n",
            "  adding: content/XMB/logs/3-conv-32-nodes1-dense-1685025822/validation/events.out.tfevents.1685025826.4d1b732e184a.169.23.v2 (deflated 77%)\n",
            "  adding: content/XMB/logs/3-conv-128-nodes0-dense-1685025741/ (stored 0%)\n",
            "  adding: content/XMB/logs/3-conv-128-nodes0-dense-1685025741/train/ (stored 0%)\n",
            "  adding: content/XMB/logs/3-conv-128-nodes0-dense-1685025741/train/events.out.tfevents.1685025741.4d1b732e184a.169.16.v2 (deflated 79%)\n",
            "  adding: content/XMB/logs/3-conv-128-nodes0-dense-1685025741/validation/ (stored 0%)\n",
            "  adding: content/XMB/logs/3-conv-128-nodes0-dense-1685025741/validation/events.out.tfevents.1685025746.4d1b732e184a.169.17.v2 (deflated 77%)\n",
            "  adding: content/XMB/logs/2-conv-32-nodes0-dense-1685025537/ (stored 0%)\n",
            "  adding: content/XMB/logs/2-conv-32-nodes0-dense-1685025537/train/ (stored 0%)\n",
            "  adding: content/XMB/logs/2-conv-32-nodes0-dense-1685025537/train/events.out.tfevents.1685025537.4d1b732e184a.169.2.v2 (deflated 76%)\n",
            "  adding: content/XMB/logs/2-conv-32-nodes0-dense-1685025537/validation/ (stored 0%)\n",
            "  adding: content/XMB/logs/2-conv-32-nodes0-dense-1685025537/validation/events.out.tfevents.1685025539.4d1b732e184a.169.3.v2 (deflated 77%)\n",
            "  adding: content/XMB/logs/2-conv-128-nodes1-dense-1685025966/ (stored 0%)\n",
            "  adding: content/XMB/logs/2-conv-128-nodes1-dense-1685025966/train/ (stored 0%)\n",
            "  adding: content/XMB/logs/2-conv-128-nodes1-dense-1685025966/train/events.out.tfevents.1685025966.4d1b732e184a.169.32.v2 (deflated 78%)\n",
            "  adding: content/XMB/logs/2-conv-128-nodes1-dense-1685025966/validation/ (stored 0%)\n",
            "  adding: content/XMB/logs/2-conv-128-nodes1-dense-1685025966/validation/events.out.tfevents.1685025969.4d1b732e184a.169.33.v2 (deflated 76%)\n",
            "  adding: content/XMB/logs/2-conv-128-nodes0-dense-1685025698/ (stored 0%)\n",
            "  adding: content/XMB/logs/2-conv-128-nodes0-dense-1685025698/train/ (stored 0%)\n",
            "  adding: content/XMB/logs/2-conv-128-nodes0-dense-1685025698/train/events.out.tfevents.1685025698.4d1b732e184a.169.14.v2 (deflated 77%)\n",
            "  adding: content/XMB/logs/2-conv-128-nodes0-dense-1685025698/validation/ (stored 0%)\n",
            "  adding: content/XMB/logs/2-conv-128-nodes0-dense-1685025698/validation/events.out.tfevents.1685025701.4d1b732e184a.169.15.v2 (deflated 77%)\n",
            "  adding: content/XMB/logs/3-conv-128-nodes2-dense-1685026219/ (stored 0%)\n",
            "  adding: content/XMB/logs/3-conv-128-nodes2-dense-1685026219/train/ (stored 0%)\n",
            "  adding: content/XMB/logs/3-conv-128-nodes2-dense-1685026219/train/events.out.tfevents.1685026219.4d1b732e184a.169.52.v2 (deflated 82%)\n",
            "  adding: content/XMB/logs/3-conv-128-nodes2-dense-1685026219/validation/ (stored 0%)\n",
            "  adding: content/XMB/logs/3-conv-128-nodes2-dense-1685026219/validation/events.out.tfevents.1685026223.4d1b732e184a.169.53.v2 (deflated 75%)\n",
            "  adding: content/XMB/logs/3-conv-64-nodes0-dense-1685025632/ (stored 0%)\n",
            "  adding: content/XMB/logs/3-conv-64-nodes0-dense-1685025632/train/ (stored 0%)\n",
            "  adding: content/XMB/logs/3-conv-64-nodes0-dense-1685025632/train/events.out.tfevents.1685025632.4d1b732e184a.169.10.v2 (deflated 79%)\n",
            "  adding: content/XMB/logs/3-conv-64-nodes0-dense-1685025632/validation/ (stored 0%)\n",
            "  adding: content/XMB/logs/3-conv-64-nodes0-dense-1685025632/validation/events.out.tfevents.1685025636.4d1b732e184a.169.11.v2 (deflated 77%)\n",
            "  adding: content/XMB/logs/1-conv-64-nodes2-dense-1685026086/ (stored 0%)\n",
            "  adding: content/XMB/logs/1-conv-64-nodes2-dense-1685026086/train/ (stored 0%)\n",
            "  adding: content/XMB/logs/1-conv-64-nodes2-dense-1685026086/train/events.out.tfevents.1685026087.4d1b732e184a.169.42.v2 (deflated 77%)\n",
            "  adding: content/XMB/logs/1-conv-64-nodes2-dense-1685026086/validation/ (stored 0%)\n",
            "  adding: content/XMB/logs/1-conv-64-nodes2-dense-1685026086/validation/events.out.tfevents.1685026089.4d1b732e184a.169.43.v2 (deflated 77%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files.download('/content/XMB/logs.zip')\n",
        "files.download('/content/XMB/model.zip')"
      ],
      "metadata": {
        "id": "VT-Loz59KTXO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "5bc36461-e583-4031-b7b3-ea1c4e7d9ccc"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_92696203-0360-400c-ac82-ddbe6b6c8f78\", \"logs.zip\", 132125)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_78879543-ba8b-4e4b-9a26-c5979758f425\", \"model.zip\", 408604)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Voltar ao topo](#ancora)"
      ],
      "metadata": {
        "id": "mrokO-mjHv-o"
      }
    }
  ]
}